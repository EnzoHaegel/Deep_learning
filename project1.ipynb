{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Model\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 36s 19ms/step - loss: 0.4969 - accuracy: 0.9482\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 41s 22ms/step - loss: 0.0796 - accuracy: 0.9764\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.0646 - accuracy: 0.9809\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 0.0572 - accuracy: 0.9831\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 0.0479 - accuracy: 0.9856\n",
      "Test Model\n",
      "Test loss: 0.3687411844730377\n",
      "Test accuracy: 0.9399999976158142\n",
      "Predict Image\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "0\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "0\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "0\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "0\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "0\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "2\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "2\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "2\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "2\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "2\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "3\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "3\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "3\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "3\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "3\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "4\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "4\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "4\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "4\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "4\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "5\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "5\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "5\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "5\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "5\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "6\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "5\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "8\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "6\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "6\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "7\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "7\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "7\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "7\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "7\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "8\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "8\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "8\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "8\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "2\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "9\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "9\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "9\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "9\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "9\n",
      "47 correct predictions out of 50\n",
      "94.0%\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "CATEGORIES = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n",
    "DATADIR = \"C:/Users/Enzo/Dataset/mnist_png/training\"\n",
    "IMG_SIZE = 28\n",
    "TESTDIR = \"C:/Users/Enzo/Dataset/mnist_png/testing\"\n",
    "\n",
    "def create_training_data():\n",
    "    \"\"\"\n",
    "    Create training data\n",
    "    \"\"\"\n",
    "    training_data = []\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(DATADIR, category)\n",
    "        class_num = CATEGORIES.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "                training_data.append([new_array, class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "    random.shuffle(training_data)\n",
    "    return training_data\n",
    "\n",
    "def create_test_data():\n",
    "    \"\"\"\n",
    "    Create test data\n",
    "    \"\"\"\n",
    "    test_data = []\n",
    "    number_of_images = 0\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(TESTDIR, category)\n",
    "        class_num = CATEGORIES.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "                test_data.append([new_array, class_num])\n",
    "                number_of_images += 1\n",
    "            except Exception as e:\n",
    "                pass\n",
    "            if number_of_images == 5:\n",
    "                number_of_images = 0\n",
    "                break\n",
    "    random.shuffle(test_data)\n",
    "    return test_data\n",
    "\n",
    "def train_model(training_data):\n",
    "    X = []\n",
    "    y = []\n",
    "    for features, label in training_data:\n",
    "        X.append(features)\n",
    "        y.append(label)\n",
    "    X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "    y = tf.keras.utils.to_categorical(y, num_classes=10)\n",
    "    model = create_model()\n",
    "    model.fit(X, y, batch_size=32, epochs=5)\n",
    "    return model\n",
    "\n",
    "def test_model(test_data, model):\n",
    "    X = []\n",
    "    y = []\n",
    "    for features, label in test_data:\n",
    "        X.append(features)\n",
    "        y.append(label)\n",
    "    X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "    y = tf.keras.utils.to_categorical(y, num_classes=10)\n",
    "    score = model.evaluate(X, y, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "\n",
    "def create_model():\n",
    "    \"\"\"\n",
    "    Create model\n",
    "    \"\"\"\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(64, [3, 3], activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(10))\n",
    "    model.add(tf.keras.layers.Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def save_model(model):\n",
    "    model.save('model.h5')\n",
    "\n",
    "def load_model():\n",
    "    model = tf.keras.models.load_model('model.h5')\n",
    "    return model\n",
    "\n",
    "def predict_image(image, model):\n",
    "    image = image.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "    prediction = model.predict(image)\n",
    "    return prediction\n",
    "\n",
    "def create_test_directory():\n",
    "    \"\"\"\n",
    "    Create test directory with 5 images of each number and save it in a directory named 'temp_test'\n",
    "    Take 5 random numbers from the test directory for each categories, and name 0000.png etc... \n",
    "    \"\"\"\n",
    "    if not os.path.exists('temp_test'):\n",
    "        os.makedirs('temp_test')\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(TESTDIR, category)\n",
    "        class_num = CATEGORIES.index(category)\n",
    "        number_of_images = 0\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "                cv2.imwrite('temp_test/' + str(class_num) + str(number_of_images) + '.png', new_array)\n",
    "                number_of_images += 1\n",
    "            except Exception as e:\n",
    "                pass\n",
    "            if number_of_images == 5:\n",
    "                number_of_images = 0\n",
    "                break\n",
    "\n",
    "def check_prediction_file():\n",
    "    \"\"\"\n",
    "    for each line of the file, split the line and check if the 2 first chars are the same\n",
    "    if they are the same add 1 to counter\n",
    "    \"\"\"\n",
    "    counter = 0\n",
    "    with open('prediction.txt', 'r') as f:\n",
    "        for line in f:\n",
    "            if line.split()[0][0] == line.split()[1][0]:\n",
    "                counter += 1\n",
    "    print(str(counter) + ' correct predictions out of 50')\n",
    "    print(str(counter / 50 * 100) + '%')\n",
    "\n",
    "def clean_prediction_file():\n",
    "    if os.path.exists('prediction.txt'):\n",
    "        os.remove('prediction.txt')\n",
    "\n",
    "def main():\n",
    "    training_data = create_training_data()\n",
    "    test_data = create_test_data()\n",
    "    print(\"Train Model\")\n",
    "    model = train_model(training_data)\n",
    "    print(\"Test Model\")\n",
    "    test_model(test_data, model)\n",
    "    create_test_directory()\n",
    "    print(\"Predict Image\")\n",
    "    clean_prediction_file()\n",
    "    for img in os.listdir('temp_test'):\n",
    "        try:\n",
    "            img_array = cv2.imread(os.path.join('temp_test', img), cv2.IMREAD_GRAYSCALE)\n",
    "            prediction = predict_image(img_array, model)\n",
    "            print(np.argmax(prediction))\n",
    "            with open('prediction.txt', 'a') as file:\n",
    "                file.write(img.split('.')[0] + \" \" + str(np.argmax(prediction)) + '\\n')\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    check_prediction_file()\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('TensoFlow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bf08deca5663318b6aca0c59a066f8ef2633fc4f11c66bcb9e7a59b1da143e5a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
